<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" href="/sites/default/files/favicon.png" type="image/x-icon" />
		<title>2012 IEEE INFOVIS Papers  | IEEE VIS</title>
    <!--<title> | IEEE VIS </title>-->
    <link type="text/css" rel="stylesheet" media="all" href="/modules/node/node.css" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/system/defaults.css" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/system/system.css" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/system/system-menus.css" />
<link type="text/css" rel="stylesheet" media="all" href="/modules/user/user.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/modules/cck/theme/content-module.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/modules/ctools/css/ctools.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/modules/date/date.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/modules/date/date_popup/themes/datepicker.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/modules/date/date_popup/themes/timeentry.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/modules/filefield/filefield.css" />
<link type="text/css" rel="stylesheet" media="all" href="/misc/farbtastic/farbtastic.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/modules/cck/modules/fieldgroup/fieldgroup.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/style.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/menutree.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.year.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.week.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.day.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.popup.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.login.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.twig.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.gowri.css" />
<link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/visweek.session.css" />
<link type="text/css" rel="stylesheet" media="print" href="/sites/ieeevis.org/themes/visweek/print.css" />
    <script type="text/javascript" src="/misc/jquery.js"></script>
<script type="text/javascript" src="/misc/drupal.js"></script>
<script type="text/javascript" src="/sites/ieeevis.org/modules/views_accordion/views-accordion.js"></script>
<script type="text/javascript" src="/sites/ieeevis.org/themes/visweek/js/slide.js"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
jQuery.extend(Drupal.settings, { "basePath": "/", "views_accordion": { "views-accordion-paper_session-page_1": { "keeponeopen": 0, "speed": 500, "firstopen": 0, "grouping": 1, "togglelinks": 1, "autocycle": 0, "autocyclespeed": 5000, "display": "div.view-display-id-page_1", "usegroupheader": 0, "header": "views-field-title" } } });
//--><!]]>
</script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
if (Drupal.jsEnabled) { $(document).ready(function() { $('body').addClass('yui-skin-sam'); } ); };
//--><!]]>
</script>
            <script type="text/javascript" src="http://ieeevis.org/sites/all/themes/year/js/jquery_cookie_plugin.js"></script>
    <script type="text/javascript" src="http://ieeevis.org/sites/all/themes/year/js/leftsidebar.js"></script>
    <script> jQuery(function(){
        jQuery('#left-nav').collapsibleNav();
        });
     </script>
    <!--[if lt IE 7]>
      <link type="text/css" rel="stylesheet" media="all" href="/sites/ieeevis.org/themes/visweek/fix-ie.css" />     
    <![endif]-->
  </head>
  <body onload="init()" class="sidebars" >
<!--[if IE]><div id="IEroot"><![endif]-->
<!-- Layout -->
          <div id="header-region" class="clear-block">
       <div id="header_bar" class="clear-block"><div id="block-block-3" class="clear-block block block-block">
<!--
-->
  <div class="content"><div id="header_text">14 - 19 OCTOBER, 2012. SEATTLE, WASHINGTON, USA</div><img src="http://ieeevis.org/sites/visweek.vgtc.org/files/header/visweek12-header.jpg"></div>
</div>
</div>
  </div>
    <div id="wrapper">
    <div id="container" class="clear-block">
      <div id="header">
        <div id="logo-floater">
                </div>

                                                    
      </div> <!-- /header -->
              <div id="sidebar-left" class="sidebar">
<div style="width:40%;padding:5%;float:left">
<iframe src="//www.facebook.com/plugins/like.php?href=https%3A%2F%2Fwww.facebook.com%2Fieeevis&amp;send=false&amp;layout=button_count&amp;width=450&amp;show_faces=false&amp;action=like&amp;colorscheme=light&amp;font&amp;height=21" scrolling="no" frameborder="0" style="border:none; overflow:hidden; width:450px; height:21px;" allowTransparency="true"></iframe>
</div>
<div style="width:40%;padding:5%;margin-left:50%;text-align:right">
<a href="https://twitter.com/ieeevis" class="twitter-follow-button" data-show-count="false" data-show-screen-name="false">Follow @ieeevis</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</div>
                    <div id="block-nodeasblock-1155" class="clear-block block block-nodeasblock">
<!--
  <h2><a href="/year/2012/left-sidebar-2012">Left Sidebar 2012</a></h2>
-->
  <div class="content"><div class="field field-type-number-integer field-field-conf-year">
    <div class="field-items">
            <div class="field-item odd">
                    2012        </div>
        </div>
</div>
<div id="left-nav"><div class="welcome-leftbar" ><div class="menu-title"><a href="http://ieeevis.org" target="_self">Welcome</a></div></div><div id="calendar-leftbar" class="open"><h3 class="menu-title" id="menu-title">Week-at-a-Glance</h3><ol class="link-leftbar"><li><a href="http://ieeevis.org/year/2012/calendar/2012-10-14">October 14, 2012</a></li><li><a href="http://ieeevis.org/year/2012/calendar/2012-10-15">October 15, 2012</a></li><li><a href="http://ieeevis.org/year/2012/calendar/2012-10-16">October 16, 2012</a></li><li><a href="http://ieeevis.org/year/2012/calendar/2012-10-17">October 17, 2012</a></li><li><a href="http://ieeevis.org/year/2012/calendar/2012-10-18">October 18, 2012</a></li><li><a href="http://ieeevis.org/year/2012/calendar/2012-10-19">October 19, 2012</a></li></ol></div><div id="session-leftbar" ><h3 class="menu-title" id="menu-title">Visweek Sessions</h3><ol class="link-leftbar"><li><a href="http://ieeevis.org/year/2012/keynote-session/all/all" target="_self">Keynote and Capstone</a></li><br /><li><a href="http://ieeevis.org/year/2012/paper-session/all/all" target="_self">Papers </a></li><li><a href="http://ieeevis.org/year/2012/paper-session/all/vis" target="_self">SciVis</a> &#183; <a href="http://ieeevis.org/year/2012/paper-session/all/infovis">InfoVis</a> &#183; <a href="http://ieeevis.org/year/2012/paper-session/all/vast">VAST</a> &#183; <a href="http://ieeevis.org/year/2012/paper-session/all/tvcg">TVCG</a></li><br /><li><a href="http://ieeevis.org/year/2012/poster-session/all/all" target="_self">Posters </a></li><br /><li><a href="http://ieeevis.org/year/2012/contest-session/all/all" target="_self">Contest & Challenge</a></li><li><a href="http://ieeevis.org/year/2012/contest-session/all/vis" target="_self">SciVis</a> &#183; <a href="http://ieeevis.org/year/2012/workshop/vast/vast-challenge">VAST</a></li><br /><li><a href="http://ieeevis.org/year/2012/panel-session/all/all" target="_self">Panels</a></li><br  /><li><a href="http://ieeevis.org/year/2012/workshop-session/all/all" target="_self">Workshops</a></li><br  /><li><a href="http://ieeevis.org/year/2012/tutorial-session/all/all" target="_self">Tutorials</a></li><br  /><li><a href="http://ieeevis.org/year/2012/public-session/all/all" target="_self">VisWeek Special Sessions</a></li><br  /><li><a href="http://visweek.org/attachments/2012_VisWeekArtShow.pdf" target="_self">Art Show Catalog</a></li><br  /><li><a href="http://ieeevis.org/year/2012/bof-session/all/all" target="_self">BOF meetings</a></li><br  /></ol></div><div class="menu-title"><a href="http://ieeevis.org/year/2012/info/overview-amp-topics/latest-news">Latest News</a><br  /></div><div class="menu-title"><a href="http://ieeevis.org/year/2012/info/exhibition/supporters-and-exhibition">Supporters and Exhibition</a><br  /></div><div class="menu-title"><a href="http://ieeevis.org/year/2012/info/registration/conference-registration">Conference Registration</a><br  /></div><div class="menu-title"><a href="http://ieeevis.org/year/2012/info/volunteer/visweek-compass-2012">Compass</a><br  /></div><div id="registration-leftbar" class="open"><h3 class="menu-title" id="menu-title">Travel and Hotel</h3><ol class="link-leftbar"><li><a href="http://ieeevis.org/year/2012/info/registration/hotel-reservations">Hotel Reservations</a></li><li><a href="http://ieeevis.org/year/2012/info/registration/getting-around-seattle">Getting around Seattle</a></li><li><a href="http://ieeevis.org/year/2012/info/registration/visa-assistance">Visa Assistance</a></li></ol></div><div class="menu-title"><a href="http://ieeevis.org/year/2012/info/volunteer/student-volunteer-information">Student Volunteers</a><br  /></div><div id="presenter-leftbar" class="open"><h3 class="menu-title" id="menu-title">Participant Information</h3><ol class="link-leftbar"><li><a href="http://ieeevis.org/year/2012/info/presenter-information/authors">Authors</a></li><li><a href="http://ieeevis.org/year/2012/info/presenter-information/poster-presenters">Poster Presenters</a></li><li><a href="http://ieeevis.org/year/2012/info/presenter-information/session-chairs">Session Chairs</a></li></ol></div><div id="cfp-leftbar" class="_blank"><h3 class="menu-title" id="menu-title">Call for Participation</h3><ol class="link-leftbar"><li>Papers</li><li><a href="http://ieeevis.org/year/2012/info/call-participation/scivis-papers" target="_self">SciVis</a>  &#183; <a href="http://ieeevis.org/year/2012/info/call-participation/infovis-papers">InfoVis</a>  &#183; <a href="http://ieeevis.org/year/2012/info/call-participation/vast-papers">VAST</a></li><br /><li><a href="http://ieeevis.org/year/2012/info/call-participation/posters" target="_self">Posters</a></li><br  /><li>Contests & Challenge</li><li><a href="http://ieeevis.org/year/2012/info/call-participation/scivis-contest">SciVis</a> &#183; <a href="http://ieeevis.org/year/2012/info/call-participation/vast-challenge">VAST</a> &#183; <a href="http://www.biovis.net/biovis/2012/info/contest" target="_blank">BioVis</a> &#183; <a href="http://ldav.org/viscontest.html" target="_blank">LDAV</a></li><br /><li><a href="http://ieeevis.org/year/2012/info/call-participation/tutorials" target="_self">Tutorials</a></li><br  /><li><a href="http://ieeevis.org/year/2012/info/call-participation/workshops" target="_self">Workshops</a></li><br  /><li><a href="http://ieeevis.org/year/2012/info/call-participation/panels" target="_self">Panels</a></li><br  /><li><a href="http://ieeevis.org/year/2012/info/call-participation/art-show" target="_self">Art Show</a></li><br  /><li><a href="http://ieeevis.org/year/2012/info/call-participation/doctoral-colloquium" target="_self">Doctoral Colloquium</a></li><br  /><li><a href="http://ieeevis.org/year/2012/info/call-participation/bof-meetings" target="_self">BOF meetings</a></li><br  /><li><a href="http://ieeevis.org/year/2012/info/call-participation/industry-involvement" target="_self">Industry Track</a></li><br  /></ol></div><div id="committee-leftbar"><h3 class="menu-title" id="menu-title">Co-located Symposia</h3><ol class="link-leftbar"><li><a href="http://www.ldav.org" target="_blank">IEEE LDAV 2012</a></li><br /><li><a href="http://www.biovis.net" target="_blank">IEEE BioVis 2012</a></li><br /></ol></div><div id="committee-leftbar" class="open"><h3 class="menu-title" id="menu-title">Committees</h3><ol class="link-leftbar"><li><a href="http://ieeevis.org/year/2012/info/committees/conference-committee" target="_self">Conference Committee</a></li><br /><li>Program Committees</li><li><a href="http://ieeevis.org/year/2012/info/committees/scivis-program-committee" target="_self">SciVis</a> &#183; <a href="http://ieeevis.org/year/2012/info/committees/infovis-program-committee">InfoVis</a> &#183; <a href="http://ieeevis.org/year/2012/info/committees/vast-program-committee">VAST</a></li><br /><li>Steering Committees</li><li><a href="http://ieeevis.org/year/2012/info/committees/scivis-steering-committee" target="_self">Vis</a> &#183; <a href="http://ieeevis.org/year/2012/info/committees/infovis-steering-committee">InfoVis</a> &#183; <a href="http://ieeevis.org/year/2012/info/committees/vast-steering-committee">VAST</a></li><br /></ol></div><div class="menu-title"><a href="mailto:info@visweek.org">Email Us</a></div><div id="archive-leftbar" class="open"><h3 id="menu-title" class="menu-title">Previous Years</h3><ol class="link-leftbar"><li><a href="http://ieeevis.org/year/2011/info/call-participation/welcome">2011</a>  &#183;<a href="http://vis.computer.org/VisWeek2010/">2010</a> &#183; <a href="http://vis.computer.org/VisWeek2009/">2009</a> &#183; <a href="http://vis.computer.org/VisWeek2008/">2008</a> &#183;</li> <li><a href="http://vis.computer.org/vis2007/">2007</a> &#183;<a href="http://vis.computer.org/vis2006/">2006</a> &#183; <a href="http://vis.computer.org/vis2005/">2005</a> &#183; <a href="http://vis.computer.org/vis2004/">2004</a> &#183;</li> <li><a href="http://vis.computer.org/vis2003/">2003</a> &#183;<a href="http://vis.computer.org/vis2002/">2002</a> &#183; <a href="http://vis.computer.org/vis2001/">2001</a> &#183; <a href="http://www.hpc.msstate.edu/conferences/vis00/">2000</a></li><li><a href="http://www.hpc.msstate.edu/conferences/vis99/">1999</a></li></ol></div></div><br /></div>
</div>
        </div>
            <div id="center"><div id="squeeze"><div class="right-corner"><div class="left-corner">
          <div class="breadcrumb"><a href="http://ieeevis.org/year/2016/info/vis-welcome/welcome">Home</a></div>                                <h2>2012 IEEE INFOVIS Papers </h2>                                                  <div class="clear-block">
                        <div class="view view-paper-session view-id-paper_session view-display-id-page_1 view-dom-id-1">
    
  
  
      <div class="view-content">
      <div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Evaluation and Methodology</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Evaluation and Methodology</div><span class="label">Date & Time :&nbsp;</span>October 16 10:30 am - 12:10 pm<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Leland Wilkinson<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->How Capacity Limits of Attention Influence Information Visualization Effectiveness </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/how-capacity-limits-attention-influence-information-visualization-effectiven"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1390?destination=node/1390"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Steve Haroz, David Whitney </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />In this paper, we explore how the capacity limits of attention influence the  
effectiveness of information visualizations. We conducted a series of  
experiments to test how visual feature type (color vs. motion), layout, and  
variety of visual elements impacted user performance. The experiments tested  
users' abilities to (1) determine if a specified target is on the screen, (2)  
detect an odd-ball, deviant target, different from the other visible objects,  
and (3) gain a qualitative overview by judging the number of unique  
categories on the screen. Our results show that the severe capacity limits of  
attention strongly modulate the effectiveness of information visualizations,  
particularly the ability to detect unexpected information. Keeping in mind  
these capacity limits, we conclude with a set of design guidelines which  
depend on a visualization's intended use.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Different Strokes for Different Folks: Visual Presentation Design between Disciplines </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/different-strokes-different-folks-visual-presentation-design-between-discipl"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1391?destination=node/1391"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Steven R. Gomez, Radu Jianu, Caroline Ziemkiewicz, Hua Guo, David H. Laidlaw </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We present an ethnographic study of design differences in visual  
presentations between academic disciplines. Characterizing design conventions  
between users and data domains is an important step in developing hypotheses,  
tools, and design guidelines for information visualization. In this paper,  
disciplines are compared at a coarse scale between four groups of fields:  
social, natural, and formal sciences; and the humanities. Two commonplace  
presentation types were analyzed: electronic slideshows and whiteboard chalk  
talks. We found design differences in slideshows using two methods: coding  
and comparing manually-selected features, like charts and diagrams, and an  
image-based analysis using PCA called eigenslides. In whiteboard talks with  
controlled topics, we observed design behaviors, including using  
representations and formalisms from a participant's own discipline, that  
suggest authors might benefit from novel assistive tools for designing  
presentations. Based on these findings, we discuss opportunities for  
visualization ethnography and human-centered authoring tools for visual  
information.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Does an Eye Tracker Tell the Truth about Visualizations?: Findings while Investigating Visualizations for Decision Making </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/does-eye-tracker-tell-truth-about-visualizations-findings-while-investigatin"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1392?destination=node/1392"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Sung-Hee Kim, Zhihua Dong, Hanjun Xian, Benjavan Upatising, Ji Soo Yi </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />For information visualization researchers, eye tracking has been a useful  
tool to investigate research participants' underlying cognitive processes by  
tracking their eye movements while they interact with visual techniques. We  
used an eye tracker to better understand why participants with a variant of a  
tabular visualization called 'SimulSort' outperformed ones with a  
conventional table and typical one-column sorting feature (i.e., Typical  
Sorting). The collected eye-tracking data certainly shed light on the  
detailed cognitive processes of the participants; SimulSort helped with  
decision-making tasks by promoting efficient browsing behavior and  
compensatory decision-making strategies. However, more interestingly, we also  
found unexpected eye-tracking patterns with Simul- Sort. We investigated the  
cause of the unexpected patterns through a crowdsourcing-based study (i.e.,  
Experiment 2), which elicited an important limitation of the eye tracking  
method: incapability of capturing peripheral vision. This particular result  
would be a caveat for other visualization researchers who plan to use an eye  
tracker in their studies. In addition, the method to use a testing stimulus  
(i.e., influential column) in Experiment 2 to verify the existence of such  
limitations would be useful for researchers who would like to verify their  
eye tracking results.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Design Study Methodology: Reflections from the Trenches and the Stacks </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/design-study-methodology-reflections-trenches-and-stacks"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1393?destination=node/1393"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Michael Sedlmair, Miriah Meyer, Tamara Munzner </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Design studies are an increasingly popular form of problem-driven  
visualization research, yet there is little guidance available about how to  
do them effectively. In this paper we reflect on our combined experience of  
conducting twenty-one design studies, as well as reading and reviewing many  
more, and on an extensive literature review of other field work methods and  
methodologies. Based on this foundation we provide definitions, propose a  
methodological framework, and provide practical guidance for conducting  
design studies. We define a design study as a project in which visualization  
researchers analyze a specific real-world problem faced by domain experts,  
design a visualization system that supports solving this problem, validate  
the design, and reflect about lessons learned in order to refine  
visualization design guidelines. We characterize two axes - a task clarity  
axis from fuzzy to crisp and an information location axis from the domain  
expert's head to the computer - and use these axes to reason about design  
study contributions, their suitability, and uniqueness from other approaches.  
The proposed methodological framework consists of 9 stages: learn, winnow,  
cast, discover, design, implement, deploy, reflect, and write. For each stage  
we provide practical guidance and outline potential pitfalls. We also  
conducted an extensive literature survey of related methodological approaches  
that involve a significant amount of qualitative field work, and compare  
design study methodology to that of ethnography, grounded theory, and action  
research.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Graphical Tests for Power Comparison of Competing Designs </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/graphical-tests-power-comparison-competing-designs"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1394?destination=node/1394"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Heike Hofmann, Lendie Follett, Mahbubul Majumder, Dianne Cook </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Lineups [4, 28] have been established as tools for visual testing similar to  
standard statistical inference tests, allowing us to evaluate the validity of  
graphical findings in an objective manner. In simulation studies [12] lineups  
have been shown as being efficient: the power of visual tests is comparable  
to classical tests while being much less stringent in terms of distributional  
assumptions made. This makes lineups versatile, yet powerful, tools in  
situations where conditions for regular statistical tests are not or cannot  
be met. In this paper we introduce lineups as a tool for evaluating the power  
of competing graphical designs. We highlight some of the theoretical  
properties and then show results from two studies evaluating competing  
designs: both studies are designed to go to the limits of our perceptual  
abilities to highlight differences between designs. We use both accuracy and  
speed of evaluation as measures of a successful design. The first study  
compares the choice of coordinate system: polar versus cartesian coordinates.  
The results show strong support in favor of cartesian coordinates in finding  
fast and accurate answers to spotting patterns. The second study is aimed at  
finding shift differences between distributions. Both studies are motivated  
by data problems that we have recently encountered, and explore using  
simulated data to evaluate the plot designs under controlled conditions.  
Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups  
provide an effective mechanism for objectively evaluating plot designs.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Graphs and Networks</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Graphs and Networks</div><span class="label">Date & Time :&nbsp;</span>October 16 02:00 pm - 03:40 pm<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Nathalie Henry-Riche<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->A User Study on Curved Edges in Graph Visualization </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/user-study-curved-edges-graph-visualization"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1395?destination=node/1395"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Kai Xu, Chris Rooney, Peter Passmore, Dong-Han Ham, Phong H. Nguyen </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Recently there has been increasing research interest in displaying graphs  
with curved edges to produce more readable visualizations. While there are  
several automatic techniques, little has been done to evaluate their  
effectiveness empirically. In this paper we present two experiments studying  
the impact of edge curvature on graph readability. The goal is to understand  
the advantages and disadvantages of using curved edges for common graph tasks  
compared to straight line segments, which are the conventional choice for  
showing edges in node-link diagrams. We included several edge variations:  
straight edges, edges with different curvature levels, and mixed straight and  
curved edges. During the experiments, participants were asked to complete  
network tasks including determination of connectivity, shortest path, node  
degree, and common neighbors. We also asked the participants to provide  
subjective ratings of the aesthetics of different edge types. The results  
show significant performance differences between the straight and curved  
edges and clear distinctions between variations of curved edges.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Compressed Adjacency Matrices: Untangling Gene Regulatory Networks </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/compressed-adjacency-matrices-untangling-gene-regulatory-networks"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1396?destination=node/1396"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Kasper Dinkla, Michel A. Westenberg, Jarke J. van Wijk </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We present a novel technique-Compressed Adjacency Matrices-for visualizing  
gene regulatory networks. These directed networks have strong structural  
characteristics: out-degrees with a scale-free distribution, in-degrees bound  
by a low maximum, and few and small cycles. Standard visualization  
techniques, such as node-link diagrams and adjacency matrices, are impeded by  
these network characteristics. The scale-free distribution of out-degrees  
causes a high number of intersecting edges in node-link diagrams. Adjacency  
matrices become space-inefficient due to the low in-degrees and the resulting  
sparse network. Compressed adjacency matrices, however, exploit these  
structural characteristics. By cutting open and rearranging an adjacency  
matrix, we achieve a compact and neatly-arranged visualization. Compressed  
adjacency matrices allow for easy detection of subnetworks with a specific  
structure, so-called motifs, which provide important knowledge about gene  
regulatory networks to domain experts. We summarize motifs commonly referred  
to in the literature, and relate them to network analysis tasks common to the  
visualization domain. We show that a user can easily find the important  
motifs in compressed adjacency matrices, and that this is hard in standard  
adjacency matrix and node-link diagrams. We also demonstrate that interaction  
techniques for standard adjacency matrices can be used for our compressed  
variant. These techniques include rearrangement clustering, highlighting, and  
filtering.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/visualizing-network-traffic-understand-performance-massively-parallel-simula"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1397?destination=node/1397"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Aaditya G. Landge, Joshua A. Levine, Katherine E. Isaacs, Abhinav Bhatele, Todd Gamblin, Martin Schu </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />The performance of massively parallel applications is often heavily impacted  
by the cost of communication among compute nodes. However, determining how to  
best use the network is a formidable task, made challenging by the ever  
increasing size and complexity of modern supercomputers. This paper applies  
visualization techniques to aid parallel application developers in  
understanding the network activity by enabling a detailed exploration of the  
flow of packets through the hardware interconnect. In order to visualize this  
large and complex data, we employ two linked views of the hardware network.  
The first is a 2D view, that represents the network structure as one of  
several simplified planar projections. This view is designed to allow a user  
to easily identify trends and patterns in the network traffic. The second is  
a 3D view that augments the 2D view by preserving the physical network  
topology and providing a context that is familiar to the application  
developers. Using the massively parallel multi-physics code pF3D as a case  
study, we demonstrate that our tool provides valuable insight that we use to  
explain and optimize pF3D's performance on an IBM Blue Gene/P system.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Memorability of Visual Features in Network Diagrams </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/memorability-visual-features-network-diagrams"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1398?destination=node/1398"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Kim Marriott, Helen Purchase, Michael Wybrow, Cagatay Goncu </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We investigate the cognitive impact of various layout features-symmetry,  
alignment, collinearity, axis alignment and orthogonality-on the recall of  
network diagrams (graphs). This provides insight into how people internalize  
these diagrams and what features should or shouldn't be utilised when  
designing static and interactive network-based visualisations. Participants  
were asked to study, remember, and draw a series of small network diagrams,  
each drawn to emphasise a particular visual feature. The visual features were  
based on existing theories of perception, and the task enabled visual  
processing at the visceral level only. Our results strongly support the  
importance of visual features such as symmetry, collinearity and  
orthogonality, while not showing any significant impact for node-alignment or  
parallel edges.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Interactive Level-of-Detail Rendering of Large Graphs </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/interactive-level-detail-rendering-large-graphs"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1399?destination=node/1399"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Michael Zinsmaier, Ulrik Brandes, Oliver Deussen, Hendrik Strobelt </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We propose a technique that allows straight-line graph drawings to be  
rendered interactively with adjustable level of detail. The approach consists  
of a novel combination of edge cumulation with density-based node aggregation  
and is designed to exploit common graphics hardware for speed. It operates  
directly on graph data and does not require precomputed hierarchies or  
meshes. As proof of concept, we present an implementation that scales to  
graphs with millions of nodes and edges, and discuss several example  
applications.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Representation and Perception</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Representation and Perception</div><span class="label">Date & Time :&nbsp;</span>October 16 04:15 pm - 05:55 pm<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Enrico Bertini<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Visual Semiotics &amp; Uncertainty Visualization: An Empirical Study </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/visual-semiotics-uncertainty-visualization-empirical-study"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1400?destination=node/1400"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Alan M. MacEachren, Robert E. Roth, James O&#039;Brien, Bonan Li, Derek Swingley, Mark Gahegan </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />This paper presents two linked empirical studies focused on uncertainty  
visualization. The experiments are framed from two conceptual perspectives.  
First, a typology of uncertainty is used to delineate kinds of uncertainty  
matched with space, time, and attribute components of data. Second, concepts  
from visual semiotics are applied to characterize the kind of visual  
signification that is appropriate for representing those different categories  
of uncertainty. This framework guided the two experiments reported here. The  
first addresses representation intuitiveness, considering both visual  
variables and iconicity of representation. The second addresses relative  
performance of the most intuitive abstract and iconic representations of  
uncertainty on a map reading task. Combined results suggest initial  
guidelines for representing uncertainty and discussion focuses on practical  
applicability of results.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Comparing Clusterings Using Bertin&#039;s Idea </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/comparing-clusterings-using-bertins-idea"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1401?destination=node/1401"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Alexander Pilhofer, Alexander Gribov, Antony Unwin </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Classifying a set of objects into clusters can be done in numerous ways,  
producing different results. They can be visually compared using contingency  
tables [27], mosaicplots [13], fluctuation diagrams [15], tableplots [20] ,  
(modified) parallel coordinates plots [28], Parallel Sets plots [18] or  
circos diagrams [19]. Unfortunately the interpretability of all these  
graphical displays decreases rapidly with the numbers of categories and  
clusterings. In his famous book A Semiology of Graphics [5] Bertin writes the  
discovery of an ordered concept appears as the ultimate point in logical  
simplification since it permits reducing to a single instant the assimilation  
of series which previously required many instants of study. Or in more  
everyday language, if you use good orderings you can see results immediately  
that with other orderings might take a lot of effort. This is also related to  
the idea of effect ordering [12], that data should be organised to reflect  
the effect you want to observe. This paper presents an efficient algorithm  
based on Bertin's idea and concepts related to Kendall's t [17], which finds  
informative joint orders for two or more nominal classification variables. We  
also show how these orderings improve the various displays and how groups of  
corresponding categories can be detected using a top-down partitioning  
algorithm. Different clusterings based on data on the environmental  
performance of cars sold in Germany are used for illustration. All presented  
methods are available in the R package extracat which is used to compute the  
optimized orderings for the example dataset.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/perception-visual-variables-tiled-wall-sized-displays-information-visualizat"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1402?destination=node/1402"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Anastasia Bezerianos, Petra Isenberg </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We present the results of two user studies on the perception of visual  
variables on tiled high-resolution wall-sized displays. We contribute an  
understanding of, and indicators predicting how, large variations in viewing  
distances and viewing angles affect the accurate perception of angles, areas,  
and lengths. Our work, thus, helps visualization researchers with design  
considerations on how to create effective visualizations for these spaces.  
The first study showed that perception accuracy was impacted most when  
viewers were close to the wall but differently for each variable (Angle,  
Area, Length). Our second study examined the effect of perception when  
participants could move freely compared to when they had a static viewpoint.  
We found that a far but static viewpoint was as accurate but less time  
consuming than one that included free motion. Based on our findings, we  
recommend encouraging viewers to stand further back from the display when  
conducting perception estimation tasks. If tasks need to be conducted close  
to the wall display, important information should be placed directly in front  
of the viewer or above, and viewers should be provided with an estimation of  
the distortion effects predicted by our work-or encouraged to physically  
navigate the wall in specific ways to reduce judgement error.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Visualizing Flow of Uncertainty through Analytical Processes </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/visualizing-flow-uncertainty-through-analytical-processes"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1403?destination=node/1403"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Yingcai Wu, Guo-Xun Yuan, Kwan-Liu Ma </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Uncertainty can arise in any stage of a visual analytics process, especially  
in data-intensive applications with a sequence of data transformations.  
Additionally, throughout the process of multidimensional, multivariate data  
analysis, uncertainty due to data transformation and integration may split,  
merge, increase, or decrease. This dynamic characteristic along with other  
features of uncertainty pose a great challenge to effective uncertainty-aware  
visualization. This paper presents a new framework for modeling uncertainty  
and characterizing the evolution of the uncertainty information through  
analytical processes. Based on the framework, we have designed a visual  
metaphor called uncertainty flow to visually and intuitively summarize how  
uncertainty information propagates over the whole analysis pipeline. Our  
system allows analysts to interact with and analyze the uncertainty  
information at different levels of detail. Three experiments were conducted  
to demonstrate the effectiveness and intuitiveness of our design.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/assessing-effect-visualizations-bayesian-reasoning-through-crowdsourcing"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1404?destination=node/1404"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Luana Micallef, Pierre Dragicevic, Jean-Daniel Fekete </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />People have difficulty understanding statistical information and are unaware  
of their wrong judgments, particularly in Bayesian reasoning. Psychology  
studies suggest that the way Bayesian problems are represented can impact  
comprehension, but few visual designs have been evaluated and only  
populations with a specific background have been involved. In this study, a  
textual and six visual representations for three classic problems were  
compared using a diverse subject pool through crowdsourcing. Visualizations  
included area-proportional Euler diagrams, glyph representations, and hybrid  
diagrams combining both. Our study failed to replicate previous findings in  
that subjects' accuracy was remarkably lower and visualizations exhibited no  
measurable benefit. A second experiment confirmed that simply adding a  
visualization to a textual Bayesian problem is of little help, even when the  
text refers to the visualization, but suggests that visualizations are more  
effective when the text is given without numerical values. We discuss our  
findings and the need for more such experiments to be carried out on  
heterogeneous populations of non-experts.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Space and Maps</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Space and Maps</div><span class="label">Date & Time :&nbsp;</span>October 17 08:30 am - 10:10 am<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Tobias Isenberg<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Organizing Search Results with a Reference Map </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/organizing-search-results-reference-map"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1405?destination=node/1405"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Arlind Nocaj, Ulrik Brandes </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We propose a method to highlight query hits in hierarchically clustered  
collections of interrelated items such as digital libraries or knowledge  
bases. The method is based on the idea that organizing search results  
similarly to their arrangement on a fixed reference map facilitates  
orientation and assessment by preserving a user's mental map. Here, the  
reference map is built from an MDS layout of the items in a Voronoi treemap  
representing their hierarchical clustering, and we use techniques from  
dynamic graph layout to align query results with the map. The approach is  
illustrated on an archive of newspaper articles.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Spatial Text Visualization Using Automatic Typographic Maps </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/spatial-text-visualization-using-automatic-typographic-maps"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1406?destination=node/1406"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Shehzad Afzal, Ross Maciejewski, Yun Jang, Niklas Elmqvist, David S. Ebert </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We present a method for automatically building typographic maps that merge  
text and spatial data into a visual representation where text alone forms the  
graphical features. We further show how to use this approach to visualize  
spatial data such as traffic density, crime rate, or demographic data. The  
technique accepts a vector representation of a geographic map and spatializes  
the textual labels in the space onto polylines and polygons based on  
user-defined visual attributes and constraints. Our sample implementation  
runs as a Web service, spatializing shape files from the OpenStreetMap  
project into typographic maps for any region.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Stacking-Based Visualization of Trajectory Attribute Data </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/stacking-based-visualization-trajectory-attribute-data"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1407?destination=node/1407"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Christian Tominski, Heidrun Schumann, Gennady Andrienko, Natalia Andrienko </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Visualizing trajectory attribute data is challenging because it involves  
showing the trajectories in their spatio-temporal context as well as the  
attribute values associated with the individual points of trajectories.  
Previous work on trajectory visualization addresses selected aspects of this  
problem, but not all of them. We present a novel approach to visualizing  
trajectory attribute data. Our solution covers space, time, and attribute  
values. Based on an analysis of relevant visualization tasks, we designed the  
visualization solution around the principle of stacking trajectory bands. The  
core of our approach is a hybrid 2D/3D display. A 2D map serves as a  
reference for the spatial context, and the trajectories are visualized as  
stacked 3D trajectory bands along which attribute values are encoded by  
color. Time is integrated through appropriate ordering of bands and through a  
dynamic query mechanism that feeds temporally aggregated information to a  
circular time display. An additional 2D time graph shows temporal information  
in full detail by stacking 2D trajectory bands. Our solution is equipped with  
analytical and interactive mechanisms for selecting and ordering of  
trajectories, and adjusting the color mapping, as well as coordinated  
highlighting and dedicated 3D navigation. We demonstrate the usefulness of  
our novel visualization by three examples related to radiation surveillance,  
traffic analysis, and maritime navigation. User feedback obtained in a small  
experiment indicates that our hybrid 2D/3D solution can be operated quite  
well.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Adaptive Composite Map Projections </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/adaptive-composite-map-projections"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1408?destination=node/1408"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Bernhard Jenny </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />All major web mapping services use the web Mercator projection. This is a  
poor choice for maps of the entire globe or areas of the size of continents  
or larger countries because the Mercator projection shows medium and higher  
latitudes with extreme areal distortion and provides an erroneous impression  
of distances and relative areas. The web Mercator projection is also not able  
to show the entire globe, as polar latitudes cannot be mapped. When selecting  
an alternative projection for information visualization, rivaling factors  
have to be taken into account, such as map scale, the geographic area shown,  
the map_s height-to-width ratio, and the type of cartographic visualization.  
It is impossible for a single map projection to meet the requirements for all  
these factors. The proposed composite map projection combines several  
projections that are recommended in cartographic literature and seamlessly  
morphs map space as the user changes map scale or the geographic region  
displayed. The composite projection adapts the map_s geometry to scale, to  
the map_s height-to-width ratio, and to the central latitude of the displayed  
area by replacing projections and adjusting their parameters. The composite  
projection shows the entire globe including poles; it portrays continents or  
larger countries with less distortio, optionally without areal distortion);  
and it can morph to the web Mercator projection for maps showing small  
regions.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Algorithms for Labeling Focus Regions </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/algorithms-labeling-focus-regions"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1409?destination=node/1409"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Martin Fink, Jan-Henrik Haunert, Andre Schulz, Joachim Spoerhase, Alexander Wolff </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Focus+context techniques, data clustering, mobile and ubiquitous  
visualization, geographic/geospatial visualization.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Design Spaces</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Design Spaces</div><span class="label">Date & Time :&nbsp;</span>October 17 10:30 am - 12:10 pm<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Tamara Munzner<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Capturing the Design Space of Sequential Space-Filling Layouts </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/capturing-design-space-sequential-space-filling-layouts"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1410?destination=node/1410"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Thomas Baudel, Bertjan Broeksema </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We characterize the design space of the algorithms that sequentially tile a  
rectangular area with smaller, fixed-surface, rectangles. This space consist  
of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each  
of these dimensions describe a particular aspect of such layout tasks. This  
class of layouts is interesting, because, beyond encompassing simple grids,  
tables and trees, it also includes all kinds of treemaps involving the  
placement of rectangles. For instance, Slice and dice, Squarified, Strip and  
Pivot layouts are various points in this five dimensional space. Many classic  
statistics visualizations, such as 100% stacked bar charts, mosaic plots and  
dimensional stacking, are also instances of this class. A few new and  
potentially interesting points in this space are introduced, such as spiral  
treemaps and variations on the strip layout. The core algorithm is  
implemented as a JavaScript prototype that can be used as a layout component  
in a variety of InfoViz toolkits.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Taxonomy-Based Glyph Design-with a Case Study on Visualizing Workflows of Biological Experiments </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/taxonomy-based-glyph-design-case-study-visualizing-workflows-biological-expe"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1411?destination=node/1411"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Eamonn Maguire, Philippe Rocca-Serra, Susanna-Assunta Sansone, Jim Davies, Min Chen </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Glyph-based visualization can offer elegant and concise presentation of  
multivariate information while enhancing speed and ease in visual search  
experienced by users. As with icon designs, glyphs are usually created based  
on the designers' experience and intuition, often in a spontaneous manner.  
Such a process does not scale well with the requirements of applications  
where a large number of concepts are to be encoded using glyphs. To alleviate  
such limitations, we propose a new systematic process for glyph design by  
exploring the parallel between the hierarchy of concept categorization and  
the ordering of discriminative capacity of visual channels. We examine the  
feasibility of this approach in an application where there is a pressing need  
for an efficient and effective means to visualize workflows of biological  
experiments. By processing thousands of workflow records in a public archive  
of biological experiments, we demonstrate that a cost-effective glyph design  
can be obtained by following a process of formulating a taxonomy with the aid  
of computation, identifying visual channels hierarchically, and defining  
application-specific abstraction and metaphors.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->An Empirical Model of Slope Ratio Comparisons </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/empirical-model-slope-ratio-comparisons"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1412?destination=node/1412"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Justin Talbot, John Gerth, Pat Hanrahan </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Comparing slopes is a fundamental graph reading task and the aspect ratio  
chosen for a plot influences how easy these comparisons are to make.  
According to Banking to 45 degrees, a classic design guideline first proposed  
and studied by Cleveland et al., aspect ratios that center slopes around 45  
degrees minimize errors in visual judgments of slope ratios. This paper  
revisits this earlier work. Through exploratory pilot studies that expand  
Cleveland et al.'s experimental design, we develop an empirical model of  
slope ratio estimation that fits more extreme slope ratio judgments and two  
common slope ratio estimation strategies. We then run two experiments to  
validate our model. In the first, we show that our model fits more generally  
than the one proposed by Cleveland et al. and we find that, in general, slope  
ratio errors are not minimized around 45 degrees. In the second experiment,  
we explore a novel hypothesis raised by our model: that visible baselines can  
substantially mitigate errors made in slope judgments. We conclude with an  
application of our model to aspect ratio selection.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/representative-factor-generation-interactive-visual-analysis-high-dimensiona"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1413?destination=node/1413"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Cagatay Turkay, Arvid Lundervold, Astri Johansen Lundervold, Helwig Hauser </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Datasets with a large number of dimensions per data item (hundreds or more)  
are challenging both for computational and visual analysis. Moreover, these  
dimensions have different characteristics and relations that result in  
sub-groups and/or hierarchies over the set of dimensions. Such structures  
lead to heterogeneity within the dimensions. Although the consideration of  
these structures is crucial for the analysis, most of the available analysis  
methods discard the heterogeneous relations among the dimensions. In this  
paper, we introduce the construction and utilization of representative  
factors for the interactive visual analysis of structures in high-dimensional  
datasets. First, we present a selection of methods to investigate the  
sub-groups in the dimension set and associate representative factors with  
those groups of dimensions. Second, we introduce how these factors are  
included in the interactive visual analysis cycle together with the original  
dimensions. We then provide the steps of an analytical procedure that  
iteratively analyzes the datasets through the use of representative factors.  
We discuss how our methods improve the reliability and interpretability of  
the analysis process by enabling more informed selections of computational  
tools. Finally, we demonstrate our techniques on the analysis of brain  
imaging study results that are performed over a large group of subjects.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Graphical Overlays: Using Layered Elements to Aid Chart Reading </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/graphical-overlays-using-layered-elements-aid-chart-reading"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1414?destination=node/1414"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Nicholas Kong, Maneesh Agrawala </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Reading a visualization can involve a number of tasks such as extracting,  
comparing or aggregating numerical values. Yet, most of the charts that are  
published in newspapers, reports, books, and on the Web only support a subset  
of these tasks. In this paper we introduce graphical overlays-visual elements  
that are layered onto charts to facilitate a larger set of chart reading  
tasks. These overlays directly support the lower-level perceptual and  
cognitive processes that viewers must perform to read a chart. We identify  
five main types of overlays that support these processes; the overlays can  
provide (1) reference structures such as gridlines, (2) highlights such as  
outlines around important marks, (3) redundant encodings such as numerical  
data labels, (4) summary statistics such as the mean or max and (5)  
annotations such as descriptive text for context. We then present an  
automated system that applies user-chosen graphical overlays to existing  
chart bitmaps. Our approach is based on the insight that generating most of  
these graphical overlays only requires knowing the properties of the visual  
marks and axes that encode the data, but does not require access to the  
underlying data values. Thus, our system analyzes the chart bitmap to extract  
only the properties necessary to generate the desired overlay. We also  
discuss techniques for generating interactive overlays that provide  
additional controls to viewers. We demonstrate several examples of each  
overlay type for bar, pie and line charts.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Text and Time</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Text and Time</div><span class="label">Date & Time :&nbsp;</span>October 18 02:00 pm - 03:40 pm<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Melanie Tory<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Facilitating Discourse Analysis with Interactive Visualization </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/facilitating-discourse-analysis-interactive-visualization"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1415?destination=node/1415"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Jian Zhao, Fanny Chevalier, Christopher Collins, Ravin Balakrishnan </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />A discourse parser is a natural language processing system which can  
represent the organization of a document based on a rhetorical structure  
tree-one of the key data structures enabling applications such as text  
summarization, question answering and dialogue generation. Computational  
linguistics researchers currently rely on manually exploring and comparing  
the discourse structures to get intuitions for improving parsing algorithms.  
In this paper, we present DAViewer, an interactive visualization system for  
assisting computational linguistics researchers to explore, compare, evaluate  
and annotate the results of discourse parsers. An iterative user-centered  
design process with domain experts was conducted in the development of  
DAViewer. We report the results of an informal formative study of the system  
to better understand how the proposed visualization and interaction  
techniques are used in the real research environment.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/whisper-tracing-spatiotemporal-process-information-diffusion-real-time"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1416?destination=node/1416"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Nan Cao, Yu-Ru Lin, Xiaohua Sun, David Lazer, Shixia Liu, Huamin Qu </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />When and where is an idea dispersed? Social media, like Twitter, has been  
increasingly used for exchanging information, opinions and emotions about  
events that are happening across the world. Here we propose a novel  
visualization design, Whisper, for tracing the process of information  
diffusion in social media in real time. Our design highlights three major  
characteristics of diffusion processes in social media: the temporal trend,  
social-spatial extent, and community response of a topic of interest. Such  
social, spatiotemporal processes are conveyed based on a sunflower metaphor  
whose seeds are often dispersed far away. In Whisper, we summarize the  
collective responses of communities on a given topic based on how tweets were  
retweeted by groups of users, through representing the sentiments extracted  
from the tweets, and tracing the pathways of retweets on a spatial  
hierarchical layout. We use an efficient flux line-drawing algorithm to trace  
multiple pathways so the temporal and spatial patterns can be identified even  
for a bursty event. A focused diffusion series highlights key roles such as  
opinion leaders in the diffusion process. We demonstrate how our design  
facilitates the understanding of when and where a piece of information is  
dispersed and what are the social responses of the crowd, for large-scale  
events including political campaigns and natural disasters. Initial feedback  
from domain experts suggests promising use for today's information  
consumption and dispersion in the wild.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/exploring-flow-factors-and-outcomes-temporal-event-sequences-outflow-visuali"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1417?destination=node/1417"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Krist Wongsuphasawat, David Gotz </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Event sequence data is common in many domains, ranging from electronic  
medical records (EMRs) to sports events. Moreover, such sequences often  
result in measurable outcomes (e.g., life or death, win or loss). Collections  
of event sequences can be aggregated together to form event progression  
pathways. These pathways can then be connected with outcomes to model how  
alternative chains of events may lead to different results. This paper  
describes the Outflow visualization technique, designed to (1) aggregate  
multiple event sequences, (2) display the aggregate pathways through  
different event states with timing and cardinality, (3) summarize the  
pathways' corresponding outcomes, and (4) allow users to explore external  
factors that correlate with specific pathway state transitions. Results from  
a user study with twelve participants show that users were able to learn how  
to use Outflow easily with limited training and perform a range of tasks both  
accurately and rapidly.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->RankExplorer: Visualization of Ranking Changes in Large Time Series Data </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/rankexplorer-visualization-ranking-changes-large-time-series-data"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1418?destination=node/1418"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Conglei Shi, Weiwei Cui, Shixia Liu, Panpan Xu, Wei Chen, Huamin Qu </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />For many applications involving time series data, people are often interested  
in the changes of item values over time as well as their ranking changes. For  
example, people search many words via search engines like Google and Bing  
every day. Analysts are interested in both the absolute searching number for  
each word as well as their relative rankings. Both sets of statistics may  
change over time. For very large time series data with thousands of items,  
how to visually present ranking changes is an interesting challenge. In this  
paper, we propose RankExplorer, a novel visualization method based on  
ThemeRiver to reveal the ranking changes. Our method consists of four major  
components: 1) a segmentation method which partitions a large set of time  
series curves into a manageable number of ranking categories; 2) an extended  
ThemeRiver view with embedded color bars and changing glyphs to show the  
evolution of aggregation values related to each ranking category over time as  
well as the content changes in each ranking category; 3) a trend curve to  
show the degree of ranking changes over time; 4) rich user interactions to  
support interactive exploration of ranking changes. We have applied our  
method to some real time series data and the case studies demonstrate that  
our method can reveal the underlying patterns related to ranking changes  
which might otherwise be obscured in traditional visualizations.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Design Considerations for Optimizing Storyline Visualizations </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/design-considerations-optimizing-storyline-visualizations"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1419?destination=node/1419"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Yuzuru Tanahashi, Kwan-Liu Ma </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Storyline visualization is a technique used to depict the temporal dynamics  
of social interactions. This visualization technique was first introduced as  
a hand-drawn illustration in XKCD's Movie Narrative Charts [21]. If properly  
constructed, the visualization can convey both global trends and local  
interactions in the data. However, previous methods for automating storyline  
visualizations are overly simple, failing to achieve some of the essential  
principles practiced by professional illustrators. This paper presents a set  
of design considerations for generating aesthetically pleasing and legible  
storyline visualizations. Our layout algorithm is based on evolutionary  
computation, allowing us to effectively incorporate multiple objective  
functions. We show that the resulting visualizations have significantly  
improved aesthetics and legibility compared to existing techniques.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Interaction</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Interaction</div><span class="label">Date & Time :&nbsp;</span>October 18 08:30 am - 10:10 am<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Miriah Meyer<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/beyond-mouse-and-keyboard-expanding-design-considerations-information-visual"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1420?destination=node/1420"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Bongshin Lee, Petra Isenberg, Nathalie Henry Riche, Sheelagh Carpendale </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />The importance of interaction to Information Visualization (InfoVis) and, in  
particular, of the interplay between interactivity and cognition is widely  
recognized [12][15][32][55][70]. This interplay, combined with the demands  
from increasingly large and complex datasets, is driving the increased  
significance of interaction in InfoVis. In parallel, there have been rapid  
advances in many facets of interaction technologies. However, InfoVis  
interactions have yet to take full advantage of these new possibilities in  
interaction technologies, as they largely still employ the traditional  
desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a  
Pointer) interfaces. In this paper, we reflect more broadly about the role of  
more natural interactions for InfoVis and provide opportunities for future  
research. We discuss and relate general HCI interaction models to existing  
InfoVis interaction classifications by looking at interactions from a novel  
angle, taking into account the entire spectrum of interactions. Our  
discussion of InfoVis-specific interaction design considerations helps us  
identify a series of underexplored attributes of interaction that can lead to  
new, more natural, interaction techniques for InfoVis.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Intelligent Graph Layout Using Many Users&#039; Input </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/intelligent-graph-layout-using-many-users-input"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1421?destination=node/1421"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Xiaoru Yuan, Limei Che, Yifan Hu, Xin Zhang </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />In this paper, we propose a new strategy for graph drawing utilizing layouts  
of many sub-graphs supplied by a large group of people in a crowd sourcing  
manner. We developed an algorithm based on Laplacian constrained distance  
embedding to merge subgraphs submitted by different users, while attempting  
to maintain the topological information of the individual input layouts. To  
facilitate collection of layouts from many people, a light-weight interactive  
system has been designed to enable convenient dynamic viewing, modification  
and traversing between layouts. Compared with other existing graph layout  
algorithms, our approach can achieve more aesthetic and meaningful layouts  
with high user preference.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->PivotPaths: Strolling through Faceted Information Spaces </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/pivotpaths-strolling-through-faceted-information-spaces"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1422?destination=node/1422"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Marian Dörk, Nathalie Henry Riche, Gonzalo Ramos, Susan Dumais </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br /><p>We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to 'take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.</p></div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Interaction Support for Visual Comparison Inspired by Natural Behavior </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/interaction-support-visual-comparison-inspired-natural-behavior"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1423?destination=node/1423"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Christian Tominski, Camilla Forsell, Jimmy Johansson </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Visual comparison is an intrinsic part of interactive data exploration and  
analysis. The literature provides a large body of existing solutions that  
help users accomplish comparison tasks. These solutions are mostly of visual  
nature and custom-made for specific data. We ask the question if a more  
general support is possible by focusing on the interaction aspect of  
comparison tasks. As an answer to this question, we propose a novel  
interaction concept that is inspired by real-world behavior of people  
comparing information printed on paper. In line with real-world interaction,  
our approach supports users (1) in interactively specifying pieces of  
graphical information to be compared, (2) in flexibly arranging these pieces  
on the screen, and (3) in performing the actual comparison of side-by-side  
and overlapping arrangements of the graphical information. Complementary  
visual cues and add-ons further assist users in carrying out comparison  
tasks. Our concept and the integrated interaction techniques are generally  
applicable and can be coupled with different visualization techniques. We  
implemented an interactive prototype and conducted a qualitative user study  
to assess the concept's usefulness in the context of three different  
visualization techniques. The obtained feedback indicates that our  
interaction techniques mimic the natural behavior quite well, can be learned  
quickly, and are easy to apply to visual comparison tasks.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->RelEx: Visualization for Actively Changing Overlay Network Specifications </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/relex-visualization-actively-changing-overlay-network-specifications"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1424?destination=node/1424"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Michael Sedlmair, Annika Frank, Tamara Munzner, Andreas Butz </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We present a network visualization design study focused on supporting  
automotive engineers who need to specify and optimize traffic patterns for  
in-car communication networks. The task and data abstractions that we derived  
support actively making changes to an overlay network, where logical  
communication specifications must be mapped to an underlying physical  
network. These abstractions are very different from the dominant use case in  
visual network analysis, namely identifying clusters and central nodes, that  
stems from the domain of social network analysis. Our visualization tool  
RelEx was created and iteratively refined through a full user-centered design  
process that included a full problem characterization phase before tool  
design began, paper prototyping, iterative refinement in close collaboration  
with expert users for formative evaluation, deployment in the field with real  
analysts using their own data, usability testing with non-expert users, and  
summative evaluation at the end of the deployment. In the summative  
post-deployment study, which entailed domain experts using the tool over  
several weeks in their daily practice, we documented many examples where the  
use of RelEx simplified or sped up their work compared to previous practices.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Sketching and Designing Visualizations</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Sketching and Designing Visualizations</div><span class="label">Date & Time :&nbsp;</span>October 18 04:15 pm - 05:55 pm<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Caroline Ziemkiewicz<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Evaluating the Effect of Style in Information Visualization </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/evaluating-effect-style-information-visualization"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1425?destination=node/1425"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Andrew Vande Moere, Martin Tomitsch, Christoph Wimmer, Christoph Boesch, Thomas Grechenig </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />This paper reports on a between-subject, comparative online study of three  
information visualization demonstrators that each displayed the same dataset  
by way of an identical scatterplot technique, yet were different in style in  
terms of visual and interactive embellishment. We validated stylistic  
adherence and integrity through a separate experiment in which a small cohort  
of participants assigned our three demonstrators to predefined groups of  
stylistic examples, after which they described the styles with their own  
words. From the online study, we discovered significant differences in how  
participants execute specific interaction operations, and the types of  
insights that followed from them. However, in spite of significant  
differences in apparent usability, enjoyability and usefulness between the  
style demonstrators, no variation was found on the self-reported depth,  
expert-rated depth, confidence or difficulty of the resulting insights. Three  
different methods of insight analysis have been applied, revealing how style  
impacts the creation of insights, ranging from higher-level pattern seeking  
to a more reflective and interpretative engagement with content, which is  
what underlies the patterns. As this study only forms the first step in  
determining how the impact of style in information visualization could be  
best evaluated, we propose several guidelines and tips on how to gather,  
compare and categorize insights through an online evaluation study,  
particularly in terms of analyzing the concise, yet wide variety of insights  
and observations in a trustworthy and reproducable manner.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Sketchy Rendering for Information Visualization </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/sketchy-rendering-information-visualization"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1426?destination=node/1426"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Jo Wood, Petra Isenberg, Tobias Isenberg, Jason Dykes, Nadia Boukhelifa, Aidan Slingsby </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We present and evaluate a framework for constructing sketchy style  
information visualizations that mimic data graphics drawn by hand. We provide  
an alternative renderer for the Processing graphics environment that  
redefines core drawing primitives including line, polygon and ellipse  
rendering. These primitives allow higher-level graphical features such as bar  
charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy  
style with a specified degree of sketchiness. The framework is designed to be  
easily integrated into existing visualization implementations with minimal  
programming modification or design effort. We show examples of use for  
statistical graphics, conveying spatial imprecision and for enhancing  
aesthetic and narrative qualities of visualization. We evaluate user  
perception of sketchiness of areal features through a series of  
stimulus-response tests in order to assess users' ability to place  
sketchiness on a ratio scale, and to estimate area. Results suggest relative  
area judgment is compromised by sketchy rendering and that its influence is  
dependent on the shape being rendered. They show that degree of sketchiness  
may be judged on an ordinal scale but that its judgement varies strongly  
between individuals. We evaluate higher-level impacts of sketchiness through  
user testing of scenarios that encourage user engagement with data  
visualization and willingness to critique visualization design. Results  
suggest that where a visualization is clearly sketchy, engagement may be  
increased and that attitudes to participating in visualization annotation are  
more positive. The results of our work have implications for effective  
information visualization design that go beyond the traditional role of  
sketching as a tool for prototyping or its use for an indication of general  
uncertainty.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->An Empirical Study on Using Visual Embellishments in Visualization </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/empirical-study-using-visual-embellishments-visualization"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1427?destination=node/1427"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Rita Borgo, Alfie Abdul-Rahman, Farhan Mohamed, Philip W. Grant, Irene Reppa, Luciano Floridi, Min C </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />In written and spoken communications, figures of speech (e.g., metaphors and  
synecdoche) are often used as an aid to help convey abstract or less tangible  
concepts. However, the benefits of using rhetorical illustrations or  
embellishments in visualization have so far been inconclusive. In this work,  
we report an empirical study to evaluate hypotheses that visual  
embellishments may aid memorization, visual search and concept comprehension.  
One major departure from related experiments in the literature is that we  
make use of a dualtask methodology in our experiment. This design offers an  
abstraction of typical situations where viewers do not have their full  
attention focused on visualization (e.g., in meetings and lectures). The  
secondary task introduces divided attention, and makes the effects of visual  
embellishments more observable. In addition, it also serves as additional  
masking in memory-based trials. The results of this study show that visual  
embellishments can help participants better remember the information depicted  
in visualization. On the other hand, visual embellishments can have a  
negative impact on the speed of visual search. The results show a complex  
pattern as to the benefits of visual embellishments in helping participants  
grasp key concepts from visualization.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/evaluating-sketchiness-visual-variable-depiction-qualitative-uncertainty"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1428?destination=node/1428"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Nadia Boukhelifa, Anastasia Bezerianos, Tobias Isenberg, Jean-Daniel Fekete </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />We report on results of a series of user studies on the perception of four  
visual variables that are commonly used in the literature to depict  
uncertainty. To the best of our knowledge, we provide the first formal  
evaluation of the use of these variables to facilitate an easier reading of  
uncertainty in visualizations that rely on line graphical primitives. In  
addition to blur, dashing and grayscale, we investigate the use of  
'sketchiness' as a visual variable because it conveys visual impreciseness  
that may be associated with data quality. Inspired by work in  
non-photorealistic rendering and by the features of hand-drawn lines, we  
generate line trajectories that resemble hand-drawn strokes of various levels  
of proficiency-ranging from child to adult strokes-where the amount of  
perturbations in the line corresponds to the level of uncertainty in the  
data. Our results show that sketchiness is a viable alternative for the  
visualization of uncertainty in lines and is as intuitive as blur; although  
people subjectively prefer dashing style over blur, grayscale and  
sketchiness. We discuss advantages and limitations of each technique and  
conclude with design considerations on how to deploy these visual variables  
to effectively depict various levels of uncertainty for line marks.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-4 accordion-item-odd accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/understanding-pen-and-touch-interaction-data-exploration-interactive-whitebo"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1429?destination=node/1429"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Jagoda Walny, Bongshin Lee, Paul Johns, Nathalie Henry Riche, Sheelagh Carpendale </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Current interfaces for common information visualizations such as bar graphs,  
line graphs, and scatterplots usually make use of the WIMP (Windows, Icons,  
Menus and a Pointer) interface paradigm with its frequently discussed  
problems of multiple levels of indirection via cascading menus, dialog boxes,  
and control panels. Recent advances in interface capabilities such as the  
availability of pen and touch interaction challenge us to re-think this and  
investigate more direct access to both the visualizations and the data they  
portray. We conducted a Wizard of Oz study to explore applying pen and touch  
interaction to the creation of information visualization interfaces on  
interactive whiteboards without implementing a plethora of recognizers. Our  
wizard acted as a robust and flexible pen and touch recognizer, giving  
participants maximum freedom in how they interacted with the system. Based on  
our qualitative analysis of the interactions our participants used, we  
discuss our insights about pen and touch interactions in the context of  
learnability and the interplay between pen and touch gestures. We conclude  
with suggestions for designing pen and touch enabled interactive  
visualization interfaces.
</div>
  </div>
</div>
      </div>
</div>
<div class="item-list views-accordion views-accordion-paper_session-page_1">
      <span class="session-event-title views-accordion-paper_session-page_1">INFOVIS Papers: Education and Popular Applications</span>
    <div id="views-accordion-paper_session-page_1">
                <span class="label">Session :&nbsp;</span><div class="session-title">Education and Popular Applications</div><span class="label">Date & Time :&nbsp;</span>October 19 08:30 am - 10:10 am<br /><span class="label">Location :&nbsp;</span>Grand Ballroom C<br /><span class="label">Chair :&nbsp;</span>Danyel Fisher<br /><span class="label">Papers :&nbsp;</span>      <div class="views-accordion-item accordion-item-0 accordion-item-odd accordion-item-first titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/deeptree-exhibit-visualizing-tree-life-facilitate-informal-learning"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1430?destination=node/1430"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Florian Block, Michael S. Horn, Brenda Caldwell Phillips, Judy Diamond, E. Margaret Evans, Chia Shen </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />In this paper, we present the DeepTree exhibit, a multi-user, multi-touch  
interactive visualization of the Tree of Life. We developed DeepTree to  
facilitate collaborative learning of evolutionary concepts. We will describe  
an iterative process in which a team of computer scientists, learning  
scientists, biologists, and museum curators worked together throughout  
design, development, and evaluation. We present the importance of designing  
the interactions and the visualization hand-in-hand in order to facilitate  
active learning. The outcome of this process is a fractal-based tree layout  
that reduces visual complexity while being able to capture all life on earth;  
a custom rendering and navigation engine that prioritizes visual appeal and  
smooth fly-through; and a multi-user interface that encourages collaborative  
exploration while offering guided discovery. We present an evaluation showing  
that the large dataset encouraged free exploration, triggers emotional  
responses, and facilitates visitor engagement and informal learning.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-1 accordion-item-even titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Living Liquid: Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/living-liquid-design-and-evaluation-exploratory-visualization-tool-museum-vi"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1431?destination=node/1431"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Joyce Ma, Isaac Liao, Kwan-Liu Ma, Jennifer Frazier </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Interactive visualizations can allow science museum visitors to explore new  
worlds by seeing and interacting with scientific data. However, designing  
interactive visualizations for informal learning environments, such as  
museums, presents several challenges. First, visualizations must engage  
visitors on a personal level. Second, visitors often lack the background to  
interpret visualizations of scientific data. Third, visitors have very  
limited time at individual exhibits in museums. This paper examines these  
design considerations through the iterative development and evaluation of an  
interactive exhibit as a visualization tool that gives museumgoers access to  
scientific data generated and used by researchers. The exhibit prototype,  
Living Liquid, encourages visitors to ask and answer their own questions  
while exploring the time-varying global distribution of simulated marine  
microbes using a touchscreen interface. Iterative development proceeded  
through three rounds of formative evaluations using think-aloud protocols and  
interviews, each round informing a key visualization design decision: (1)  
what to visualize to initiate inquiry, (2) how to link data at the  
microscopic scale to global patterns, and (3) how to include additional data  
that allows visitors to pursue their own questions. Data from visitor  
evaluations suggests that, when designing visualizations for public  
audiences, one should (1) avoid distracting visitors from data that they  
should explore, (2) incorporate background information into the  
visualization, (3) favor understandability over scientific accuracy, and (4)  
layer data accessibility to structure inquiry. Lessons learned from this case  
study add to our growing understanding of how to use visualizations to  
actively engage learners with scientific data.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-2 accordion-item-odd titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->Visualizing Student Histories Using Clustering and Composition </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/visualizing-student-histories-using-clustering-and-composition"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1432?destination=node/1432"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />David Trimm, Penny Rheingans, Marie desJardins </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />While intuitive time-series visualizations exist for common datasets, student  
course history data is difficult to represent using traditional visualization  
techniques due its concurrent nature. A visual composition process is  
developed and applied to reveal trends across various groupings. By working  
closely with educators, analytic strategies and techniques are developed to  
leverage the visualization composition to reveal unknown trends in the data.  
Furthermore, clustering algorithms are developed to group common course-grade  
histories for further analysis. Lastly, variations of the composition process  
are implemented to reveal subtle differences in the underlying data. These  
analytic tools and techniques enabled educators to confirm expected trends  
and to discover new ones.
</div>
  </div>
</div>
              <div class="views-accordion-item accordion-item-3 accordion-item-even accordion-item-last titles">  
  <div class="views-field-title">
                <span class="field-content"><div><!--Author: -->SnapShot: Visualization to Propel Ice Hockey Analytics </div></span>
  </div>
  
  <div class="views-field-nid-1">
                <span class="field-content"></span>
  </div>
  
  <div class="views-field-nid">
                <span class="field-content"><div class="paper-links"><a title="Read entire document" href="http://ieeevis.org/year/2012/paper/infovis/snapshot-visualization-propel-ice-hockey-analytics"><img src="http://ieeevis.org/sites/all/themes/visweek/images/read_more.png"></a><a title="Get update notification" href="http://ieeevis.org/notifications/subscribe/1/thread/nid/1433?destination=node/1433"><img src="http://ieeevis.org/sites/all/themes/visweek/images/subscribe.png"></a></div></span>
  </div>
  
  <div class="views-field-field-paper-authors-value">
                <div class="field-content"><div><span class="label">Authors: </span><br />Hannah Pileggi, Charles D. Stolper, J. Michael Boyle, John T. Stasko </div></div>
  </div>
  
  <div class="views-field-field-paper-abstract-value">
                <div class="field-content"><span class="label">Abstract : </span><br />Sports analysts live in a world of dynamic games flattened into tables of  
numbers, divorced from the rinks, pitches, and courts where they were  
generated. Currently, these professional analysts use R, Stata, SAS, and  
other statistical software packages for uncovering insights from game data.  
Quantitative sports consultants seek a competitive advantage both for their  
clients and for themselves as analytics becomes increasingly valued by teams,  
clubs, and squads. In order for the information visualization community to  
support the members of this blossoming industry, it must recognize where and  
how visualization can enhance the existing analytical workflow. In this  
paper, we identify three primary stages of today's sports analyst's routine  
where visualization can be beneficially integrated: 1) exploring a dataspace;  
2) sharing hypotheses with internal colleagues; and 3) communicating findings  
to stakeholders.Working closely with professional ice hockey analysts, we  
designed and built SnapShot, a system to integrate visualization into the  
hockey intelligence gathering process. SnapShot employs a variety of  
information visualization techniques to display shot data, yet given the  
importance of a specific hockey statistic, shot length, we introduce a  
technique, the radial heat map. Through a user study, we received encouraging  
feedback from several professional analysts, both independent consultants and  
professional team personnel.
</div>
  </div>
</div>
      </div>
</div>
    </div>
  
    
  
  
  
</div>           </div>
                </div></div></div></div> <!-- /.left-corner, /.right-corner, /#squeeze, /#center -->
              <div id="sidebar-right" class="sidebar">
                    <div id="block-block-8" class="clear-block block block-block">
<!--
-->
  <div class="content"><div class="sidebar-title" id="important-dates">Important Dates</div>
<div class="event-title"><strike><strong>March 21st</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/paper-submission-guidelines">Papers - abstract deadline</a></strike></div>
<div class="event-title"><strike><strong>March 31st</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/paper-submission-guidelines">Papers - submission deadline</a></strike></div>
<div class="event-title"><strike><strong>April 30th</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/tutorials">Tutorials - proposal submission deadline</a><br><a href="">Workshops - proposal submission deadline</a></strike></div>
<div class="event-title"><strike><strong>May 25th</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/doctoral-colloquium">Doctoral Colloquium - submission deadline</a></strike></div>
<div class="event-title"><strike><strong>June 6th</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/paper-submission-guidelines">Papers - notification of results of first review cycle</a></strike></div>
<div class="event-title"><strike><strong>June 12th</strong><br><a  href="http://www.vissv.org/visweektasksystem/htdocs/shirtcontest.html
">Student Volunteers - T-shirt design contest deadline</a></strike></div>
<div class="event-title"><strike><strong>June 15th</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/panels">Panels - submission deadline</a></strike></div>
<div class="event-title"><strike><strong>June 24th</strong></strike><br><a	href="http://ieeevis.org/year/2016/info/call-participation/posters">Posters - submission deadline</a></strike></div>
<div class="event-title"><strike><strong>June 27th</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/paper-submission-guidelines">Papers - submission deadline for second review cycle</a></strike></div>
<div class="event-title"><strike><strong>July 11th</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/paper-submission-guidelines">Papers - final notification</a></strike></div>
<div class="event-title"><strike><strong>August 1st</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/paper-submission-guidelines">Papers - camera-ready submission deadline</a>
<br><a href="http://www.vissv.org/visweektasksystem/htdocs/application.html">Student Volunteers - application deadline</a>
<br><a href="http://www.vissv.org/visweektasksystem/htdocs/tshirt.php">Student Volunteers - T-shirt design vote deadline</a>
</strike></div>
<div class="event-title"><strong>September 4th</strong><br><a	href="http://ieeevis.org/year/2016/info/call-participation/meetups">Meetups - proposal submission deadline</a></div>
<div class="event-title"><strong>September 9th</strong><br><a	href="#">VIS registration - early bird deadline</a></div>

</div>
</div>
<div id="block-block-6" class="clear-block block block-block">
<!--
-->
  <div class="content"><script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js"></script><script>
function guessYear()
{
    // Tries to guess current year based on the HREF
    try {
        var year = window.location.pathname.split("/")[2];
        return Number(year) || 2016;
    } catch (e) {
        console.error("Could not guess year! Defaulting to 2016", window.location);
        return 2016;
    }
}

sponsorsJson = [
    {
        "class": "Platinum",
        "href": "http://www.kaust.edu.sa/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/logo_with_text_white.png",
        "year": 2011
    },
    {
        "class": "Platinum",
        "href": "http://www.microsoft.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/ms-logo_bL.png",
        "year": 2011
    },
    {
        "class": "Platinum",
        "href": "http://www.tableausoftware.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/Padded_Tableau_Logo.jpg",
        "year": 2011
    },
    {
        "class": "Gold",
        "href": "http://www.nlm.nih.gov/",
        "src": "/attachments\u2026pporterssites/visweek.vgtc.org/files/supporter/NLMLOGOBlueReproOutline.png",
        "year": 2011
    },
    {
        "class": "Gold",
        "href": "http://www.sci.utah.edu/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/SCI-logo-mono.png",
        "year": 2011
    },
    {
        "class": "Silver",
        "href": "http://www.research.ibm.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/ibm_high.gif",
        "year": 2011
    },
    {
        "class": "Silver",
        "href": "http://www.intel.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/intel.png",
        "year": 2011
    },
    {
        "class": "Silver",
        "href": "http://www.pnl.gov/computing/resources/nvac.stm",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/NVAC_DHS.jpg",
        "year": 2011
    },
    {
        "class": "Silver",
        "href": "http://www.pnl.gov/",
        "src": "/attachments\u2026porterssites/visweek.vgtc.org/files/supporter/PNNL_Color_Logo_Vertical.jpg",
        "year": 2011
    },
    {
        "class": "Silver",
        "href": "http://www.velir.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/VelirLogo_3-colorPMS.jpg",
        "year": 2011
    },
    {
        "class": "Publisher",
        "href": "http://www.akpeters.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/ak_peters.jpg",
        "year": 2011
    },
    {
        "class": "Publisher",
        "href": "http://www.morganclaypool.com",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/MCP_logo_02.jpg",
        "year": 2011
    },
    {
        "class": "Platinum Plus",
        "href": "http://www.ibm.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/IBM.jpeg",
        "year": 2012
    },
    {
        "class": "Platinum Plus",
        "href": "http://www.intel.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/intel_0.png",
        "year": 2012
    },
    {
        "class": "Platinum Plus",
        "href": "http://www.kaust.edu.sa/visweek",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/KAUST_0.png",
        "year": 2012
    },
    {
        "class": "Platinum Plus",
        "href": "http://www.microsoft.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/ms-logo_bL_0.png",
        "year": 2012
    },
    {
        "class": "Platinum Plus",
        "href": "http://www.tableausoftware.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/tableau_cmyk.png",
        "year": 2012
    },
    {
        "class": "Gold",
        "href": "http://www.pnnl.gov/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/PNNL.png",
        "year": 2012
    },
    {
        "class": "Silver",
        "href": "http://www.att.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/ATT_new_ai.png",
        "year": 2012
    },
    {
        "class": "Silver",
        "href": "http://www.battelle.org/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/Battelle%20Logo.jpg",
        "year": 2012
    },
    {
        "class": "Silver",
        "href": "http://www.igd.fraunhofer.de/en/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/IGD.png",
        "year": 2012
    },
    {
        "class": "Silver",
        "href": "http://www.infinitez.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/infinitez.png",
        "year": 2012
    },
    {
        "class": "Silver",
        "href": "http://www.nlm.nih.gov/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/NLM.png",
        "year": 2012
    },
    {
        "class": "Silver",
        "href": "http://www.sci.utah.edu/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/sci-logo-one-color.png",
        "year": 2012
    },
    {
        "class": "Silver",
        "href": "http://www.vacommunity.org/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/VACommunityLogo.png",
        "year": 2012
    },
    {
        "class": "Academic",
        "href": "http://www.purdue.edu/discoverypark/vaccine/index.php",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/vaccine_logo.png",
        "year": 2012
    },
    {
        "class": "Publisher",
        "href": "http://www.akpeters.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/akPeters.png",
        "year": 2012
    },
    {
        "class": "Publisher",
        "href": "http://www.morganclaypool.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/MCP.jpeg",
        "year": 2012
    },
    {
        "class": "Symposium Sponsor",
        "href": "http://www.agilent.com/",
        "src": "/attachments\u2026erssites/visweek.vgtc.org/files/supporter/Agilent_4c_CorporateSig-noHL.JPG",
        "year": 2012
    },
    {
        "class": "Symposium Sponsor",
        "href": "http://www.autodesk.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/Autodesk_logo.jpg",
        "year": 2012
    },
    {
        "class": "Symposium Sponsor",
        "href": "http://www.kitware.com/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/kitware.png",
        "year": 2012
    },
    {
        "class": "Symposium Sponsor",
        "href": "http://www.nature.com/nmeth/index.html",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/NMeth%20logo.png",
        "year": 2012
    },
    {
        "class": "Symposium Sponsor",
        "href": "http://www.sci.utah.edu/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/sci-logo-one-color_0.png",
        "year": 2012
    },
    {
        "class": "Symposium Sponsor",
        "href": "http://www.nationwidechildrens.org/battelle-center-for-mathematical-medicine",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/nationwide-childrens.png",
        "year": 2012
    },
    {
        "class": "Symposium Sponsor",
        "href": "http://energy.gov/",
        "src": "/attachments/supporterssites/visweek.vgtc.org/files/supporter/doe.png",
        "year": 2012
    },
    {
        "class": "Platinum",
        "href": "http://www.cisco.com/",
        "src": "/attachments/supporters/tmp/Cisco_Logo.png",
        "year": 2013
    },
    {
        "class": "Platinum",
        "href": "http://www.nvidia.com/",
        "src": "/attachments/supporters/tmp/nvidia.jpg",
        "year": 2013
    },
    {
        "class": "Gold",
        "href": "http://www.microsoft.com/",
        "src": "/attachments/supporters/tmp/ms-logo.jpg",
        "year": 2013
    },
    {
        "class": "Silver",
        "href": "http://www.agilent.com/",
        "src": "/attachments/supporters/tmp/agilent_logo.png",
        "year": 2013
    },
    {
        "class": "Silver",
        "href": "http://www.ibm.com/",
        "src": "/attachments/supporters/tmp/ibm-logo.png",
        "year": 2013
    },
    {
        "class": "Silver",
        "href": "http://www.kaust.edu.sa/",
        "src": "/attachments/supporters/tmp/Untitled.png",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.autodesk.com/",
        "src": "/attachments/supporters/tmp/autodesk-logo-rgb-color-logo-black-text-medium.png",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.mathmed.org/",
        "src": "/attachments/supporters/tmp/battelle.png",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.kitware.com/",
        "src": "/attachments/supporters/tmp/kitware_0.gif",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.pnnl.gov/",
        "src": "/attachments/supporters/tmp/PNNL_Color_Logo_Horizontal1_os.png",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.sci.utah.edu/",
        "src": "/attachments/supporters/tmp/sci-logo-one-color.png",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.tableausoftware.com/",
        "src": "/attachments/supporters/tmp/tableau_cmyk.png",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.vis-sense.eu/",
        "src": "/attachments/supporters/tmp/VIS-SENSE_Logo_Web.png",
        "year": 2013
    },
    {
        "class": "Bronze",
        "href": "http://www.zspace.com/",
        "src": "/attachments/supporters/tmp/zspace.gif",
        "year": 2013
    },
    {
        "class": "Start Up/Small Company Sponsor",
        "href": "http://forio.com/",
        "src": "/attachments/supporters/tmp/VECTOR_LOGO.png",
        "year": 2013
    },
    {
        "class": "Start Up/Small Company Sponsor",
        "href": "http://www.zoomdata.com/",
        "src": "/attachments/supporters/tmp/ZD_logo_big_cropped.png",
        "year": 2013
    },
    {
        "class": "Publisher",
        "href": "http://www.crcpress.com/",
        "src": "/attachments/supporters/tmp/CRCblue.jpg",
        "year": 2013
    },
    {
        "class": "Academic",
        "href": "http://www.cc.gatech.edu/",
        "src": "/attachments/supporters/tmp/GT-logo.png",
        "year": 2013
    },
    {
        "class": "Academic",
        "href": "http://www.mica.edu/",
        "src": "/attachments/supporters/tmp/mica-logo.png",
        "year": 2013
    },
    {
        "class": "Academic",
        "href": "http://www.purdue.edu/discoverypark/vaccine/index.php",
        "src": "/attachments/supporters/tmp/vaccine_logo.png",
        "year": 2013
    },
    {
        "class": "Non-Profit",
        "href": "http://www.anl.gov/",
        "src": "/attachments/supporters/tmp/argonne.jpg",
        "year": 2013
    },
    {
        "class": "Diamond",
        "href": "http://www.inria.fr/",
        "src": "/attachments/supporters/tmp/in.png",
        "year": 2014
    },
    {
        "class": "Diamond",
        "href": "http://www.tableausoftware.com/",
        "src": "/attachments/supporters/tmp/tableau_cmyk_lg.jpg",
        "year": 2014
    },
    {
        "class": "Platinum",
        "href": "http://www.cea.fr/",
        "src": "/attachments/supporters/tmp/CEA_GB_logotype.jpg",
        "year": 2014
    },
    {
        "class": "Platinum",
        "href": "http://www.jcdecaux.com/en/",
        "src": "/attachments/supporters/tmp/JCDecaux.png",
        "year": 2014
    },
    {
        "class": "Gold",
        "href": "http://www.digiteo.fr/-en-",
        "src": "/attachments/supporters/tmp/digiteo%202-logo%20gb%20baseline.png",
        "year": 2014
    },
    {
        "class": "Gold",
        "href": "https://www.igd.fraunhofer.de/",
        "src": "/attachments/supporters/tmp/fr.png",
        "year": 2014
    },
    {
        "class": "Gold",
        "href": "http://www.microsoft.com/",
        "src": "/attachments/supporters/tmp/ms-logo_0.jpg",
        "year": 2014
    },
    {
        "class": "Silver",
        "href": "http://www.autodesk.com/",
        "src": "/attachments/supporters/tmp/autodesk2.png",
        "year": 2014
    },
    {
        "class": "Silver",
        "href": "http://www.campus-paris-saclay.fr/en/Idex-Paris-Saclay/Les-Lidex/Paris-Saclay-Center-for-Data-Science",
        "src": "/attachments/supporters/tmp/CDS.png",
        "year": 2014
    },
    {
        "class": "Silver",
        "href": "http://here.com/",
        "src": "/attachments/supporters/tmp/here.JPG",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.adobe.com/",
        "src": "/attachments/supporters/tmp/adobe_logo_standard.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://edf/com",
        "src": "/attachments/supporters/tmp/edf.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://google.com/",
        "src": "/attachments/supporters/tmp/google.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.ibm.com/",
        "src": "/attachments/supporters/tmp/IBM_logo.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.iscpif.fr/",
        "src": "/attachments/supporters/tmp/logo_m_orange-DIM.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.irt-systemx.fr/",
        "src": "/attachments/supporters/tmp/sx.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.kitware.com/",
        "src": "/attachments/supporters/tmp/PrintLogo_NoGradient.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.nvidia.com/",
        "src": "/attachments/supporters/tmp/NVLogo_2D.JPG",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.scvis.fr/",
        "src": "/attachments/supporters/tmp/LOGO-SCV2.png",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.techviz.net/",
        "src": "/attachments/supporters/tmp/techviz.jpg",
        "year": 2014
    },
    {
        "class": "Bronze",
        "href": "http://www.telecom-paristech.fr/nc/formation-et-innovation-dans-le-numerique.html",
        "src": "/attachments/supporters/tmp/logo-TPT.png",
        "year": 2014
    },
    {
        "class": "Publisher",
        "href": "http://www.crcpress.com/",
        "src": "/attachments/supporters/tmp/CRC_RGB2.png",
        "year": 2014
    },
    {
        "class": "Publisher",
        "href": "http://www.morganclaypool.com/",
        "src": "/attachments/supporters/tmp/MCP_logo_02.jpg",
        "year": 2014
    },
    {
        "class": "Publisher",
        "href": "http://www.springer.com/",
        "src": "/attachments/supporters/tmp/Springer.jpg",
        "year": 2014
    },
    {
        "class": "Start Up/Small Company Sponsor",
        "href": "http://www.aldecis.com/",
        "src": "/attachments/supporters/tmp/aldecis-logo.jpg",
        "year": 2014
    },
    {
        "class": "Start Up/Small Company Sponsor",
        "href": "https://www.dkrz.de/",
        "src": "/attachments/supporters/tmp/dkrz_logo2.png",
        "year": 2014
    },
    {
        "class": "Start Up/Small Company Sponsor",
        "href": "http://www.nsa.gov/",
        "src": "/attachments/supporters/tmp/NSA2.jpg",
        "year": 2014
    },
    {
        "class": "Academic",
        "href": "http://www.anl.gov/",
        "src": "/attachments/supporters/tmp/ANL_4C_P_H2.png",
        "year": 2014
    },
    {
        "class": "Academic",
        "href": "http://www.ocadu.ca/",
        "src": "/attachments/supporters/tmp/OCAD.png",
        "year": 2014
    },
    {
        "class": "Academic",
        "href": "http://www.sci.utah.edu/",
        "src": "/attachments/supporters/tmp/SCI-logo-transparent-black-med.png",
        "year": 2014
    },
    {
        "class": "Academic",
        "href": "http://www.visualdecision.fr/",
        "src": "/attachments/supporters/tmp/logo-vd-petit.jpg",
        "year": 2014
    },
    {
        "class": "Academic",
        "href": "http://www.visus.uni-stuttgart.de/en/institute.html",
        "src": "/attachments/supporters/tmp/VISUS2.png",
        "year": 2014
    },
    {
        "class": "Academic",
        "href": "http://www.vrvis.at/",
        "src": "/attachments/supporters/tmp/VRVis-Logo.png",
        "year": 2014
    },
    {
        "class": "Diamond",
        "href": "http://www.nsf.gov/",
        "src": "/attachments/supporters/tmp/nsf_t.png",
        "year": 2015
    },
    {
        "class": "Diamond",
        "href": "http://www.tableausoftware.com/",
        "src": "/attachments/supporters/tmp/tab.png",
        "year": 2015
    },
    {
        "class": "Platinum",
        "href": "http://www.autodesk.com/",
        "src": "/attachments/supporters/tmp/autodesk_2015.png",
        "year": 2015
    },
    {
        "class": "Platinum",
        "href": "http://www.intel.com/",
        "src": "/attachments/supporters/tmp/intel_2015.png",
        "year": 2015
    },
    {
        "class": "Gold",
        "href": "http://www.bloomberg.com/ux",
        "src": "/attachments/supporters/tmp/bloomberg_t.png",
        "year": 2015
    },
    {
        "class": "Gold",
        "href": "http://www.nvidia.com/",
        "src": "/attachments/supporters/tmp/NVLogo_2D.PNG",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://www.adobe.com/",
        "src": "/attachments/supporters/tmp/adobe_2015.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://att.com/",
        "src": "/attachments/supporters/tmp/att1.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://www.disneyresearch.com/",
        "src": "/attachments/supporters/tmp/DR.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://www.google.com/",
        "src": "/attachments/supporters/tmp/google2015.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://iacs.seas.harvard.edu/",
        "src": "/attachments/supporters/tmp/iacs.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://ibm.com/",
        "src": "/attachments/supporters/tmp/IBM_t.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://www.kaust.edu.sa/",
        "src": "/attachments/supporters/tmp/kaust.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://www.kitware.com/",
        "src": "/attachments/supporters/tmp/kitware.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://research.microsoft.com/",
        "src": "/attachments/supporters/tmp/MSR_t.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "http://www.pnnl.gov/",
        "src": "/attachments/supporters/tmp/PNNL2.PNG",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "https://www.nlm.nih.gov/",
        "src": "/attachments/supporters/tmp/nlm.png",
        "year": 2015
    },
    {
        "class": "Silver",
        "href": "https://uncharted.software/",
        "src": "/attachments/supporters/tmp/Uncharted-rgb-Vertical_27Aug2015.png",
        "year": 2015
    },
    {
        "class": "Bronze",
        "href": "http://www.act.org/",
        "src": "/attachments/supporters/tmp/ACT-logo-Blue-cmyk.png",
        "year": 2015
    },
    {
        "class": "Bronze",
        "href": "https://www.continuum.io/",
        "src": "/attachments/supporters/tmp/Anaconda_Logo_0702.png",
        "year": 2015
    },
    {
        "class": "Bronze",
        "href": "http://www.mechdyne.com/",
        "src": "/attachments/supporters/tmp/mechdyne.png",
        "year": 2015
    },
    {
        "class": "Bronze",
        "href": "http://plot.ly/",
        "src": "/attachments/supporters/tmp/plotly_logo_for_web_outlined.png",
        "year": 2015
    },
    {
        "class": "Bronze",
        "href": "http://renci.org/",
        "src": "/attachments/supporters/tmp/renci_ss.png",
        "year": 2015
    },
    {
        "class": "Bronze",
        "href": "http://vize.io/",
        "src": "/attachments/supporters/tmp/New_Logo-VIZE-transparent-small.png",
        "year": 2015
    },
    {
        "class": "Academic",
        "href": "http://www.niu.edu/",
        "src": "/attachments/supporters/tmp/NIU_2015.png",
        "year": 2015
    },
    {
        "class": "Academic",
        "href": "https://www.orau.org/",
        "src": "/attachments/supporters/tmp/ORAU.png",
        "year": 2015
    },
    {
        "class": "Academic",
        "href": "http://www.sci.utah.edu/",
        "src": "/attachments/supporters/tmp/sci.png",
        "year": 2015
    },
    {
        "class": "Academic",
        "href": "http://www.uic.edu/",
        "src": "/attachments/supporters/tmp/uic1.png",
        "year": 2015
    },
    {
        "class": "Academic",
        "href": "https://www.visus.uni-stuttgart.de/en/institute.html",
        "src": "/attachments/supporters/tmp/VISUS.png",
        "year": 2015
    },
    {
        "class": "Academic",
        "href": "http://www.vrvis.at/",
        "src": "/attachments/supporters/tmp/vrvis_t.png",
        "year": 2015
    },
    {
        "class": "Publisher",
        "href": "https://www.crcpress.com/",
        "src": "/attachments/supporters/tmp/CRC.png",
        "year": 2015
    },
    {
        "class": "Publisher",
        "href": "http://www.morganclaypool.com/",
        "src": "/attachments/supporters/tmp/mcp.png",
        "year": 2015
    },
    {
        "class": "Publisher",
        "href": "http://www.springer.com/",
        "src": "/attachments/supporters/tmp/Springer_cmyk.png",
        "year": 2015
    },
    {
        "class": "Diamond",
        "href": "http://www.nsf.gov/",
        "src": "/attachments/supporters/tmp/nsf_t.png",
        "year": 2016
    },
    {
        "class": "Diamond",
        "href": "http://www.tableausoftware.com/",
        "src": "/attachments/supporters/tmp/tab.png",
        "year": 2016
    },
    {
        "class": "Platinum",
        "href": "http://www.nvidia.com/",
        "src": " /attachments/supporters/tmp/NVLogo_2D.PNG",
        "year": 2016
    },
    {
        "class": "Gold",
        "href": "http://www.ibm.com/",
        "src": "/attachments/supporters/tmp/IBM_t.png",
        "year": 2016
    },
    {
        "class": "Gold",
        "href": "http://www.intel.com/",
        "src": "/attachments/supporters/tmp/intel_2015.png",
        "year": 2016
    },
    {
        "class": "Gold",
        "href": "http://research.microsoft.com/",
        "src": "/attachments/supporters/tmp/MSR_t.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "http://www.adobe.com/",
        "src": "/attachments/supporters/tmp/adobe_2015.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "https://uncharted.software/",
        "src": "/attachments/supporters/tmp/Uncharted-rgb-Vertical_27Aug2015.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "http://iacs.seas.harvard.edu/",
        "src": "/attachments/supporters/tmp/iacs.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "https://bocoup.com/",
        "src": "/attachments/bocoup-datavis-logo-vertical-2016.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "http://www.kaust.edu.sa/",
        "src": "/attachments/supporters/tmp/kaust.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "http://www.disneyresearch.com/",
        "src": "/attachments/supporters/tmp/DR.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "https://www.nlm.nih.gov/",
        "src": "/attachments/supporters/2016/nlm.png",
        "year": 2016
    },
    {
        "class": "Silver",
        "href": "https://www.mica.edu/",
        "src": "/attachments/supporters/2016/mica.png",
        "year": 2016
    },
    {
	"class": "Bronze",
	"href": "http://elevenpeppers.com/",
	"src": "/attachments/supporters/eleven_peppers.png",
	"year": 2016
    },
    {
	"class": "Bronze",
	"href": "http://rstudio.com/",
	"src": "/attachments/supporters/tmp/RStudio.png",
	"year": 2016
    },
    {
	"class": "Bronze",
	"href": "http://www.capdigital.com/en/",
	"src": "/attachments/supporters/2016/cap_digital.png",
	"year": 2016
    },
    {
        "class": "Bronze",
        "href": "http://www.google.com/",
        "src": "/attachments/supporters/tmp/google2015.png",
        "year": 2016
    },
    {
        "class": "NonProfit/Small Company/Startup",
        "href": "http://www.act.org/",
        "src": "/attachments/supporters/tmp/ACT-logo-Blue-cmyk.png",
	"year": 2016
    },
    {
        "class": "NonProfit/Small Company/Startup",
        "href": "http://www.sentimetrix.com/",
        "src": "/attachments/supporters/2016/sentimetrix.png",
	"year": 2016
    },
    {
	"class": "Academic",
	"href": "http://www.sci.utah.edu/",
	"src": "/attachments/supporters/tmp/sci.png",
	"year": 2016
    },
    {
	"class": "Academic",
	"href": "http://www.vrvis.at/",
	"src": "/attachments/supporters/tmp/vrvis_t.png",
	"year": 2016
    },
    {
	"class": "Academic",
	"href": "http://citi.clemson.edu/viz/",
	"src": "/attachments/supporters/2016/clemson_ccit.png",
	"year": 2016
    },
    {
	"class": "Publisher",
	"href": "http://www.morganclaypool.com/",
	"src": "/attachments/supporters/tmp/mcp.png",
	"year": 2016
    },
    {
	"class": "Publisher",
	"href": "http://www.springer.com/",
	"src": "/attachments/supporters/tmp/Springer_cmyk.png",
	"year": 2016
    },
    {
        "class": "Publisher",
        "href": "https://www.crcpress.com/",
        "src": "/attachments/supporters/tmp/CRC.png",
        "year": 2016
    }
];

function loadSponsors() {
    // d3.json("/js/all_sponsors.json", function(json) {
        var json = sponsorsJson;
        var year = guessYear();
        var div = d3.select("#supporters");
        var currentClass;
        for (var i=0; i<json.length; ++i) {
            var o = json[i];
            if (o.year !== year)
                continue;
            if (o.class !== currentClass) {
                currentClass = o.class;
                div.append("br");
                div.append("div").classed("supporter-level", true).text(o.class);
            }
            div.append("center")
                .append("a").attr("href", o.href)
                .append("img").attr("src", o.src).attr("width", "120");
        }
    // });
}

// The neverending train of disgusting hacks continues.
if (guessYear() !== 2016) {
    d3.select(document.getElementById("important-dates").parentNode).style("display", "none");
}

</script><div class="sidebar-title" id="supporters">Supporters</br> <a href="http://ieeevis.org/year/2016/info/exhibition/supporters-and-exhibition">(Become one)</a></div><script>loadSponsors();</script></div>
</div>
        </div>
          </div> <!-- /container -->
  </div>
<!-- /layout -->
  <div id="footer"><div id="block-block-4" class="clear-block block block-block">
<!--
-->
  <div class="content"><div class="footer-image"><img src="http://ieeevis.org/sites/visweek.vgtc.org/files/footer/visweek12-footer.jpg"></div><div class="footer-message"> © 2012 IEEE. Sponsored by the IEEE Computer Society Visualization and Graphics Technical Committee.</div></div>
</div>
</div>
    <!--[if IE]></div><![endif]--></body>
</html>
