---
title: Test of Time Awards
layout: page
permalink: /info/awards/test-of-time-awards
contact: "web@ieeevis.org"
---

## To improve the future, we must reflect on our past.

The IEEE VIS Test of Time Award is an accolade given to recognize *articles* published at previous conferences whose contents are still vibrant and useful today and have had a major impact and influence within and beyond the visualization community.

By making the awards at the conference opening we hope to encourage researchers to aim  to produce work that is forward looking and has transformational potential. We're trying to build on our heritage to establish an ambitious future by making it clear at the conference opening that we want participants to aspire to be writing the papers that will be relevant in 10 and 20 years.

Papers are selected for each of the three conferences (VAST, InfoVis and SciVis) by Test of Time Awards panels. These panels are appointed by each conference Steering Committee.

The decisions are based on objective measures such as the numbers of citations, and more subjective ones such as the quality and longevity and influence of ideas, outreach, uptake and effect not only in the research community, but also within application domains and visualization practice.

VAST currently considers conferences 10 years prior to the current conference.

InfoVis currently considers conferences 10 and 20 years prior to the current conference.

SciVis currently considers 15 and 25 years prior to the current conference.

## VAST 2009: 10 Years Test of Time Award 
**Parallel tag clouds to explore and analyze faceted text corpora**  
Authors: Christopher Collins, Fernanda B. Viegas, and Martin Wattenberg <br>
<a href="https://doi.org/10.1109/VAST.2009.5333443">https://doi.org/10.1109/VAST.2009.5333443</a><br>

Do court cases differ from place to place? What kind of picture do we get by looking at a country's collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity.

## InfoVis 
**1999: Cluster and calendar based visualization of time series data**  
Authors: J.J. Van Wijk, E.R. Van Selow <br>
<a href="https://doi.org/10.1109/INFVIS.1999.801851">https://doi.org/10.1109/INFVIS.1999.801851</a><br>

A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented.

**2009: A Nested Model for Visualization Design and Validation**  
Authors: Tamara Munzner <br>
<a href="https://doi.org/10.1109/TVCG.2009.111">https://doi.org/10.1109/TVCG.2009.111</a><br>

We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.

## SciVis
**1994: An evaluation of reconstruction filters for volume rendering**  
Authors: Stephen Marschner and Richard Lobb <br>
<a href="https://doi.org/10.1109/VISUAL.1994.346331">https://doi.org/10.1109/VISUAL.1994.346331</a><br>

To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation. We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the interpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter.

**2004: Simplifying Flexible Isosurfaces Using local Geometric Measures**  
Authors: Hamish Carr, Jack Snoeyink, Michiel van de Panne <br>
<a href="https://doi.org/10.1109/VISUAL.2004.96">https://doi.org/10.1109/VISUAL.2004.96</a><br>

The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.


